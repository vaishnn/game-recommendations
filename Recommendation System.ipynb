{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\nThis notebook builds a content-based recommendation system for Steam games. The goal is to recommend games to users based on their preferences, using game metadata and user review data. We'll connect to a MariaDB database, process the data, engineer features, and use text similarity and popularity to generate recommendations.","metadata":{}},{"cell_type":"markdown","source":"## Installing MariaDB Dependencies\n\nBefore we can connect to the MariaDB database, we need to ensure the required system libraries are installed. The following code installs the MariaDB development library using the system's package manager. This is necessary for Python packages to communicate with MariaDB.\n","metadata":{}},{"cell_type":"code","source":"# For Important MariaDB Connector\nimport subprocess\nimport sys\ndef install_dep_mariadb():\n    \"\"\"\n    This is for installing maria db lib using terminal\n    \"\"\"\n    command = ['sudo', 'apt-get', 'install', 'libmariadb-dev']\n    try:\n        print(f\"Executing command: {' '.join(command)}\")\n        result = subprocess.run(command, check=True, capture_output=True, text=True)\n        print(result.stdout)\n    except Exception as e:\n        print(f\"I Don't know some error ig {e}\")\ninstall_dep_mariadb()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:28:14.769664Z","iopub.execute_input":"2025-09-01T06:28:14.770487Z","iopub.status.idle":"2025-09-01T06:28:23.408477Z","shell.execute_reply.started":"2025-09-01T06:28:14.770460Z","shell.execute_reply":"2025-09-01T06:28:23.407298Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Installing Python Packages\n\nWe need several Python libraries for data processing, machine learning, and database connectivity. This cell installs `pandas`, `sqlalchemy`, `scikit-learn`, and `mariadb` so we can proceed with data loading and analysis.\n","metadata":{}},{"cell_type":"code","source":"# Install required packages (for notebook environments)\n!pip install pandas sqlalchemy scikit-learn mariadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:28:23.410033Z","iopub.execute_input":"2025-09-01T06:28:23.410321Z","iopub.status.idle":"2025-09-01T06:28:37.551199Z","shell.execute_reply.started":"2025-09-01T06:28:23.410292Z","shell.execute_reply":"2025-09-01T06:28:37.550056Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importing Libraries and Setting Up Database Connection\n\nHere, we import all the necessary Python libraries for feature engineering, database connection, and machine learning. We also securely retrieve database credentials using Kaggle's secrets manager. The SQL query aggregates game metadata, genres, categories, and tags from multiple tables, filtering for games with enough reviews to be meaningful.\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries for feature engineering, database connection, and ML\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nimport pickle\nimport pandas as pd\nfrom sqlalchemy import create_engine\nimport mariadb\nfrom kaggle_secrets import UserSecretsClient\nimport joblib\n\n# Retrieve database credentials securely from Kaggle secrets\nuser_secrets = UserSecretsClient()\nDB_HOST = user_secrets.get_secret(\"DB_HOST\")\nDB_NAME = user_secrets.get_secret(\"DB_NAME\")\nDB_PASSWORD = user_secrets.get_secret(\"DB_PASSWORD\")\nDB_PORT = user_secrets.get_secret(\"DB_PORT\")\nDB_USER = user_secrets.get_secret(\"DB_USER\")\n\n# SQL query to fetch game data and aggregate genres, categories, and tags\n# Here I used above than 100 due to the limitations of processing provided by kaggle\nsql_query = \"\"\"\nSELECT\n    a.id, a.name, a.short_description, a.positive_reviews, a.negative_reviews, a.achievements_count, a.recommendations,\n    GROUP_CONCAT(DISTINCT g.name SEPARATOR ' ') AS genres,\n    GROUP_CONCAT(DISTINCT c.name SEPARATOR ' ') AS categories,\n    GROUP_CONCAT(DISTINCT t.name SEPARATOR ' ') AS tags\nFROM\n    apps a\nLEFT JOIN app_genres ag ON a.id = ag.app_id\nLEFT JOIN genres g ON ag.genre_id = g.id\nLEFT JOIN app_categories ac ON a.id = ac.app_id\nLEFT JOIN categories c ON ac.category_id = c.id\nLEFT JOIN app_tags atg ON a.id = atg.app_id\nLEFT JOIN tags t ON atg.tag_id = t.id\nWHERE\n    a.type = 'game' AND a.positive_reviews + a.negative_reviews > 100\nGROUP BY\n    a.id;\n\"\"\"\n\n# Create SQLAlchemy engine and load data into DataFrame\nengine = create_engine(\n    f\"mariadb+mariadbconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n)\ndfMain = pd.read_sql(sql_query, engine)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:29:50.639734Z","iopub.execute_input":"2025-09-01T06:29:50.640068Z","iopub.status.idle":"2025-09-01T06:30:44.720683Z","shell.execute_reply.started":"2025-09-01T06:29:50.640044Z","shell.execute_reply":"2025-09-01T06:30:44.719970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading and Preparing Data and feature Engineering\n\nWe load the game data from the database into a pandas DataFrame. To prepare for feature engineering, we fill missing values and ensure numeric columns are properly typed. This step is crucial for robust downstream processing. To compare games based on their content, we combine genres, categories, tags, and descriptions into a single text feature called \"soup\". We also add keywords to represent achievement-heavy games and those with overwhelmingly positive reviews. This enriched text representation helps our recommendation engine understand both content and sentiment.\n","metadata":{}},{"cell_type":"code","source":"# Prepare DataFrame for feature engineering\ndf = dfMain.copy()\ndf.fillna('', inplace=True)\ndf.head()\n\n# Convert review and achievement columns to integers, fill missing values\nfor col in ['positive_reviews', 'negative_reviews', 'achievements_count', 'recommendations']:\n    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n\n# Ensure text columns are filled with empty strings if missing\nfor col in ['genres', 'categories', 'tags', 'short_description']:\n    df[col] = df[col].fillna(\"\")\n\ndef create_soup(x):\n    text_features = f\"{x['genres']} {x['categories']} {x['tags']} {x['short_description']}\"\n    achievement_keywords = ' '.join(['achievementheavy'] * (x['achievements_count'] // 20))\n    sentiment_keywords = ''\n    total_reviews = x['positive_reviews'] + x['negative_reviews']\n    if total_reviews > 20 and (x['positive_reviews'] / total_reviews) > 0.80:\n        sentiment_keywords = ' '.join(['overwhelminglypositive'] * 5)\n    return f\"{text_features} {achievement_keywords} {sentiment_keywords}\"\n\n# Create a 'soup' feature for each game for text-based similarity\ndf['soup'] = df.apply(create_soup, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:31:23.646925Z","iopub.execute_input":"2025-09-01T06:31:23.647315Z","iopub.status.idle":"2025-09-01T06:31:24.188343Z","shell.execute_reply.started":"2025-09-01T06:31:23.647289Z","shell.execute_reply":"2025-09-01T06:31:24.187584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Text Vectorization and Similarity Calculation\n\nWe use `CountVectorizer` to convert the \"soup\" text into a matrix of token counts, ignoring common English stop words. Then, we compute cosine similarity between all games, which quantifies how similar each game is to every other based on their metadata and descriptions. We also scale the popularity score for each game, which will help balance recommendations between popular and niche titles.\n","metadata":{}},{"cell_type":"code","source":"# Vectorize the 'soup' feature, removing common English stop words\ncount = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(df['soup'])\n\n# Compute cosine similarity between all games\ncosine_sim = cosine_similarity(count_matrix, count_matrix)\n\n# Map game IDs to DataFrame indices for fast lookup\nid_to_index = pd.Series(df.index, index=df['id']).to_dict()\n\n# Scale popularity score for use in recommendations\nscaler = MinMaxScaler()\ndf['popularity_score'] = scaler.fit_transform(df[['recommendations']])\n\nnumber_of_game_recommendations = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:31:26.905449Z","iopub.execute_input":"2025-09-01T06:31:26.905776Z","iopub.status.idle":"2025-09-01T06:32:03.117810Z","shell.execute_reply.started":"2025-09-01T06:31:26.905750Z","shell.execute_reply":"2025-09-01T06:32:03.116970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Recommendation Function\n\nThis function takes a list of user-preferred games and computes recommendations. It combines similarity scores, user preferences (like or opposite), and popularity to rank games. The function excludes the input games from the results and returns the top recommendations.\n","metadata":{}},{"cell_type":"code","source":"def get_recommendations(input_games: list, niche_factor: float, cosine_sim, dataframe, id_map):\n    \"\"\"\n    Given a list of input games, return top recommendations based on similarity and popularity.\n    Supports boosting or reducing scores based on user preference (like/opposite).\n    \"\"\"\n    total_scores = pd.Series(0.0, index = dataframe.index)\n    input_game_indices = []\n\n    for game in input_games:\n        game_id = game['id']\n        multiplier = game.get('multiplier', 1.0)\n        pref_type = game.get('type', 'like')\n\n        if game_id not in id_map:\n            print(f\"Warning: Game with ID '{game_id}' not found. Skipping.\")\n            continue\n\n        idx = id_map[game_id]\n        input_game_indices.append(idx)\n\n        sim_scores = cosine_sim[idx]\n        adjusted_scores = -sim_scores if pref_type == \"opposite\" else sim_scores\n        total_scores += (adjusted_scores * multiplier)\n\n    # Adjust scores by popularity and niche factor\n    adjustment = 1 + (dataframe['popularity_score'] * niche_factor)\n    total_scores = total_scores * adjustment\n\n    # Exclude input games from recommendations\n    total_scores = total_scores.drop(input_game_indices, errors='ignore')\n    top_10_indices = total_scores.sort_values(ascending=False).head(10).index\n\n    return dataframe['name'].iloc[top_10_indices]\n\n# Example user input: list of games with preferences\nuser_input_by_id = [\n    {'id': 25, 'multiplier': 2.0, 'type': 'like'},      # Cyberpunk 2077\n    {'id': 1245620, 'multiplier': 1.0, 'type': 'like'}, # ELDEN RING\n    # {'id': 1349130, 'multiplier': 1.0, 'type': 'like'}  # Gollum (commented out)\n]\n\n# Get recommendations and print results\npopular_recs = get_recommendations(user_input_by_id, 1.0, cosine_sim, df, id_to_index)\nprint(\"\\n\" + \"=\"*50)\nprint(\"RECOMMENDATIONS (POPULARITY MODE):\")\nprint(popular_recs)\nprint(\"=\"*50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:32:15.019467Z","iopub.execute_input":"2025-09-01T06:32:15.020447Z","iopub.status.idle":"2025-09-01T06:32:15.036875Z","shell.execute_reply.started":"2025-09-01T06:32:15.020421Z","shell.execute_reply":"2025-09-01T06:32:15.035907Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saving Model Artifacts\n\nFinally, we save the computed similarity matrix, processed DataFrame, and ID-to-index mapping as pickle files. This allows us to reuse these artifacts later without recomputing, making the recommendation system efficient and scalable.\n","metadata":{}},{"cell_type":"code","source":"with open('cosine_sim.pkl', 'wb') as f:\n    pickle.dump(cosine_sim, f)\nwith open('dataframe.pkl', 'wb') as f:\n    pickle.dump(df, f)\nwith open('id_to_index.pkl', 'wb') as f:\n    pickle.dump(id_to_index, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:32:19.654753Z","iopub.execute_input":"2025-09-01T06:32:19.655112Z","iopub.status.idle":"2025-09-01T06:32:31.494400Z","shell.execute_reply.started":"2025-09-01T06:32:19.655088Z","shell.execute_reply":"2025-09-01T06:32:31.493439Z"}},"outputs":[],"execution_count":null}]}
